{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a4e61d",
   "metadata": {},
   "source": [
    "# SLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1ee034",
   "metadata": {},
   "source": [
    "## 단층 퍼셉트론 신경망 구조\n",
    "\n",
    "단층 퍼셉트론은 일련의 퍼셉트론을 한줄로 배치하여 입력벡터 하나로부터 출력 벡터 하나를 얻어내는 가장 기본적인 신경망 구조이다.\n",
    "single layer perceptron의 경우 입력 벡터로부터 출력 벡터를 얻어내려면 출력 벡터의 크기, 즉 출력 벡터가 담고 있어야 할 스칼라 성분 만큼의 퍼셉트론이 필요하다.\n",
    "\n",
    "## 신경망의 세가지 기본 출력 유형과 회귀 분석\n",
    "\n",
    "인공지능 알고리즘의 출력 내용을 세분화하면 회귀 분석, 이진 판단, 선택 분류로 구성된다.\n",
    "\n",
    "a) 회귀 분석 : 회귀 분석은 어떤 특징값 하나를 숫자로 추정하여 출력한다.\n",
    "b) 이진 판단 : 이진 판단은 '예'나 '아니오' 가운데 하나를 택해 출력한다.\n",
    "c) 선택 분류 : 선택 분류는 몇 가지 후보 항목 중 하나를 골라 선택 결과를 출력한다.\n",
    "\n",
    "인공지능 알고리즘의 출력은 이 세가지 유형의 반복이거나 혼합이다.\n",
    "\n",
    "회귀(regression)은 옛 상태로 돌아간다는 뜻이다. 통계학에서는 연속형 변수 사이의 모형을 구한 뒤 적합도를 측정하는 분석 방법을 회귀 분석이라 한다. 입력으로 주어진 값들을 근거로 미지의 변숫 값을 추정하고 예측하는 데 주로 이용된다. 딥러닝 알고리즘의 값 추정 역시 신경망 모델이 입력 데이터를 근거로 출력값을 추정하는 것이기에 통계학에서 이야기하는 회귀 분석의 한 방법에 해당한다.\n",
    "\n",
    "### 회귀 분석과 평균제곱오차(MSE, Mean Square Error) 손실 함수\n",
    "\n",
    "회귀 분석 출력을 내는 딥러닝 신경망은 값의 추정에 근거가 되는 입력 데이터가 잘 주어질수록 그리고 신경망 구조가 이 데이터에 적합한 구조이고 학습이 잘 될수록 더 정확한 추정값을 만든다.\n",
    "딥러닝 학습(혹은 이외의 회귀 학습에서도 적용되는 말임)을 하려면 추정값이 따로 주어지는 정답과 비교할 때 얼마나 정확한지를 요약해서 보여주는 정량적 지표가 필요하다.\n",
    "회귀 분석에서는 추정값이 얼마나 정확한지 평가할 때 보통 MSE, Mean Square Error를 평가 지표로 삼는다. 평균제곱오차란 출력 각 성분에 대해 추정값과 정답 사이의 차이인 오차를 제곱한 후 모두 합해 전체 성분 수로 나눈 값이다. 정확한 추정에 가까울수록 0과 가까운 값을 가지게 된다.\n",
    "딥러닝에서는 값이 항상 0 이상이며 추정이 정확해질수록 값이 작아지는 성질이 있으며 미분도 가능한 평가지표를 정의한 후 이를 최소화하는 것을 목표로 학습을 수행한다. 이런 성질의 평가지표를 손실 함수(loss function) 혹은 비용함수(Cost function)이라고 한다. 여기에 함수라는 표현이 붙는 이유는 입력이나 신경망의 가중치에 따라 그 값이 달라지기 때문이며 그냥 줄여서 손실 혹은 비용이라고 부르기도 한다.\n",
    "\n",
    "## 경사하강법과 역전파\n",
    "\n",
    "경사하강법(Gradient Descent Algorithm)은 함수의 기울기를 반복 계산하면서 이 기울기에 따라 함숫값이 낮아지는 방향으로 이동하는 기본적인 딥러닝 학습 알고리즘이다. 딥러닝은 기본적으로 가변 파라미터를 갖는 신경망 구조를 설정한 후 학습을 통해 파라미터값들을 조절하여 신경망이 원하는 동작을 수행하도록 만드는 인공지능 기법이다. Perceptron에서 파라미터란 가중치와 편향을 말한다.\n",
    "딥러닝에서 경사하강법은 mini-batch 입력 데이터에 대해 순전파(Forward Propagation)와 역전파(Backward Propagation)을 번갈아 수행하는 과정을 반복하면서 신경망 파라미터들을 원하는 방향으로 바꾸어나간다.\n",
    "\n",
    "순전파(Forward Propagation)란 입력 데이터에 대해 신경망 구조를 따라가면서 현재의 파라미터값들을 이용해 손실 함숫값을 계산하는 과정을 말한다.\n",
    "\n",
    "역전파(Backward Propagation)란 순전파 계산 과정을 역순으로 거슬러가면서 손실 함숫값에 직간접적으로 영향을 미친 모든 성분에 대하여 손실 기울기를 계산하는 과정을 말한다.\n",
    "\n",
    "## Hyperparameter\n",
    "\n",
    "딥러닝 모델을 개발하다보면 여러가지 값이 등장한다. 이들을 크게 4가지로 구분할 수 있다.\n",
    "\n",
    "a) 외부에서 주어지는 값\n",
    "    학습에 사용되는 데이터처럼 외부에서 주어지는 값이다. 이 값은 신경망 개발자 입장에서는 직접 손댈 수 없는 고정된 값이며 개발 시점에는 정확하게 알기도 어렵다. 좋은 결과를 얻으려면 잘 만들어진 데이터가 필요하다.\n",
    "b) 각종 중간 계산 결과\n",
    "    순전파나 역전파 처리 과정에서 생성되는 각종 중간 계산 결과이다. 학습 과정에서 최소화 대상이 되는 손실 함숫값이나 성능에 대한 평가 지표로서 신경망의 출력 유형에 따라 별도로 정의될 정확도는 지속적인 관찰의 대상이 되기도 한다. 하지만 이 값은 프로그램 실행 결과로 얻어지므로 신경망 개발자는 좋은 값이 나오도록 애쓸 뿐 달리 손댈 수 없다.\n",
    "c) 파라미터\n",
    "    학습이 진행됨에 따라 갑싱 변하고 그러면서 순전파와 역전파 처리에 계속 이용되는 값이다. 이미 소개한 파라미터로서 퍼셉트론의 가중치나 편향이 이에 해당한다. 결국, 딥러닝 연구는 딥러닝 모델의 구조, 즉 파라미터의 구조를 잘 잡는 방법과 값을 적절한 조합으로 만드는 학습 방법을 탐구하는 것으로 요약할 수 있다.\n",
    "d) 하이퍼파라미터\n",
    "    학습률(Learning rate)나 학습 횟수, 미니배치 크기처럼 딥러닝 모델의 구조나 학습 과정에 영향을 미치는 각종 상숫값이다. 딥러닝에서는 이들을 하이퍼파라미터라고 부르는데 하이퍼파라미터는 딥러닝 알고리즘이 실행되는 동안은 값이 변하지 않는 상수이지만 그렇다고 항상 고정불변인 것은 아니다. 마음에 드는 학습 결과를 얻기 위해 개발자가 끊임없이 값을 바꾸어가며 실험하는 도중에, 개발자가 변경할 수 있다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
