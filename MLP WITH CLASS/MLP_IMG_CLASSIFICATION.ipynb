{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4b3bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "\n",
    "np.random.seed(1234)\n",
    "\n",
    "def randomize():\n",
    "        np.random.seed(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b73d22d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(object):\n",
    "    def __init__(self, name, dataset):\n",
    "        self.name = name\n",
    "        self.dataset = dataset\n",
    "        self.is_training = False\n",
    "        \n",
    "        if not hasattr(self, 'rand_std'):\n",
    "            self.rand_std = 0.030\n",
    "        \n",
    "    def __str__(self):\n",
    "        return '{}/{}'.format(self.name, self.dataset)\n",
    "    \n",
    "    def exec_all(self, epoch_count = 10, batch_size = 10, learning_rate = 0.001,\n",
    "                report = 0, show_cnt = 3):\n",
    "        self.train(epoch_count, batch_size, learning_rate, report)\n",
    "        self.test()\n",
    "        if show_cnt > 0:\n",
    "            self.visualize(show_cnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f914ad7",
   "metadata": {},
   "source": [
    "### __init__\n",
    "\n",
    "is_training flag is only turned on during training, and will be turned off during validation or evaluation process. It is a processing technique that behaves differently when it is learning and when it is not\n",
    "\n",
    "### exec_all\n",
    "\n",
    "exec_all serves as the main function that runs the entire process. It calls the training, evaluation, and visualization methods in that order.\n",
    "\n",
    "exec_All method also passes several hyperparameters specified as parameters to each required method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "027498e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MlpModel(Model):\n",
    "    def __init__(self, name, dataset, hconfigs):\n",
    "        super(MlpModel, self).__init__(name, dataset)\n",
    "        self.init_parameters(hconfigs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb075a24",
   "metadata": {},
   "source": [
    "Call the init_parameter method to prepare parameters for the neural network to use. The hidden layer configuration of the multilayer perceptron is determined by the hconfigs argument value passed to the init_parameters() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e27edc8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_init_parameters(self, hconfigs):\n",
    "    self.hconfigs = hconfigs\n",
    "    self.pm_hiddens = []\n",
    "    \n",
    "    prev_shape = self.dataset.input_shape\n",
    "    \n",
    "    for hconfig in hconfigs:\n",
    "        pm_hidden, prev_shape = self.alloc_layer_param(prev_shape, hconfig)\n",
    "        self.pm_hiddens.append(pm_hidden)\n",
    "    \n",
    "    output_cnt = int(np.prod(self.dataset.output_shape))\n",
    "    self.pm_output, _ = self.alloc_layer_param(prev_shape, output_cnt)\n",
    "    \n",
    "def mlp_alloc_layer_param(self, input_shape, hconfig):\n",
    "    input_cnt = np.prod(input_shape)\n",
    "    output_cnt = hconfig\n",
    "    \n",
    "    weight, bias = self.alloc_param_pair([input_cnt, output_cnt])\n",
    "    \n",
    "    return {'w' : weight, 'b' : bias}, output_cnt\n",
    "\n",
    "def mlp_alloc_param_pair(self, shape):\n",
    "    weight = np.random.normal(0, self.rand_std, shape)\n",
    "    bias = np.zeros([shape[-1]])\n",
    "    return weight, bias\n",
    "\n",
    "MlpModel.init_parameters = mlp_init_parameters\n",
    "MlpModel.alloc_layer_param = mlp_alloc_layer_param\n",
    "MlpModel.alloc_param_pair = mlp_alloc_param_pair"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2b0605",
   "metadata": {},
   "source": [
    "Information such as input/output vector size is obtained not as a global variable, but as a property value of the dataset object.\n",
    "\n",
    "Save created parameters as object variables instead of gloabl variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "74031379",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model_train(self, epoch_count = 10, batch_size = 10, \\\n",
    "                   learning_rate = 0.001, report = 0):\n",
    "    self.learning_rate = learning_rate\n",
    "    \n",
    "    batch_count = int(self.dataset.train_count() / batch_size)\n",
    "    time1 = time2 = int(time.time())\n",
    "    \n",
    "    if report != 0:\n",
    "        print('Model {} train started:'.format(self.name))\n",
    "    \n",
    "    for epoch in range(epoch_count):\n",
    "        costs = []\n",
    "        accs = []\n",
    "        self.dataset.shuffle_train_data(batch_size * batch_count)\n",
    "        \n",
    "        for n in range(batch_count):\n",
    "            trX, trY = self.dataset.get_train_data(batch_size, n)\n",
    "            cost, acc = self.train_step(trX, trY)\n",
    "            costs.append(cost)\n",
    "            accs.append(acc)\n",
    "            \n",
    "        if report > 0 and (epoch + 1) % report == 0:\n",
    "            vaX, vaY = self.dataset.get_validate_data(100)\n",
    "            acc = self.eval_accuracy(vaX, vaY)\n",
    "            time3 = int(time.time())\n",
    "            tm1, tm2 = time3 - time2, time3 - time1\n",
    "            \n",
    "            self.dataset.train_prt_result(epoch + 1, costs, accs, acc, tm1, tm2)\n",
    "            time2 = time3\n",
    "    \n",
    "    tm_total = int(time.time()) - time1\n",
    "    print('Model {} train ended in {} secs'.format(self.name, tm_total))\n",
    "    \n",
    "MlpModel.train = mlp_model_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1afaacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model_test(self):\n",
    "    teX, teY = self.dataset.get_test_data()\n",
    "    time1 = int(time.time())\n",
    "    acc = self.eval_accuracy(teX, teY)\n",
    "    time2 = int(time.time())\n",
    "    \n",
    "    self.dataset.test_prt_result(self.name, acc, time2 - time1)\n",
    "    \n",
    "MlpModel.test = mlp_model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5349fac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_model_visualize(self, num):\n",
    "    print('Model {} visualization'.format(self.name))\n",
    "    deX, deY = self.dataset.get_visualize_data(num)\n",
    "    est = self.get_estimate(deX)\n",
    "    self.dataset.visualize(deX, est, deY)\n",
    "    \n",
    "MlpModel.visualize = mlp_model_visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08aa6ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_train_step(self, x, y):\n",
    "    self.is_training = True\n",
    "    \n",
    "    output, aux_nn = self.forward_neuralnet(x)\n",
    "    loss, aux_pp = self.forward_postproc(output, y)\n",
    "    accuracy = self.eval_accuracy(x, y, output)\n",
    "    \n",
    "    G_loss = 1.0\n",
    "    G_output = self.backprop_postproc(G_loss, aux_pp)\n",
    "    self.backprop_neuralnet(G_output, aux_nn)\n",
    "    \n",
    "    self.is_training = False\n",
    "    \n",
    "    return loss, accuracy\n",
    "\n",
    "MlpModel.train_step = mlp_train_step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e69ae4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_forward_neuralnet(self, x):\n",
    "    hidden = x\n",
    "    aux_layers = []\n",
    "    \n",
    "    for n, hconfig in enumerate(self.hconfigs):\n",
    "        hidden, aux = self.forward_layer(hidden, hconfig, self.pm_hiddens[n])\n",
    "        aux_layers.append(aux)\n",
    "    \n",
    "    output, aux_out = self.forward_layer(hidden, None, self.pm_output)\n",
    "    \n",
    "    return output, [aux_out, aux_layers]\n",
    "\n",
    "def mlp_backprop_neuralnet(self, G_output, aux):\n",
    "    aux_out, aux_layers = aux\n",
    "    \n",
    "    G_hidden = self.backprop_layer(G_output, None, self.pm_output, aux_out)\n",
    "    \n",
    "    for n in reversed(range(len(self.hconfigs))):\n",
    "        hconfig, pm, aux = self.hconfigs[n], self.pm_hiddens[n], aux_layers[n]\n",
    "        G_hidden = self.backprop_layer(G_hidden, hconfig, pm, aux)\n",
    "    \n",
    "    return G_hidden\n",
    "\n",
    "MlpModel.forward_neuralnet = mlp_forward_neuralnet\n",
    "MlpModel.backprop_neuralnet = mlp_backprop_neuralnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "201ef49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_forward_layer(self, x, hconfig, pm):\n",
    "    y = np.matmul(x, pm['w']) + pm['b']\n",
    "    if hconfig is not None:\n",
    "        y = relu(y)\n",
    "    \n",
    "    return y, [x, y]\n",
    "\n",
    "def mlp_backprop_layer(self, G_y, hconfig, pm, aux):\n",
    "    x, y = aux\n",
    "    \n",
    "    if hconfig is not None:\n",
    "        G_y = relu_derv(y) * G_y\n",
    "    \n",
    "    g_y_weight = x.transpose()\n",
    "    g_y_input = pm['w'].transpose()\n",
    "   \n",
    "    G_weight = np.matmul(g_y_weight, G_y)\n",
    "    G_bias = np.sum(G_y, axis = 0)\n",
    "    G_input = np.matmul(G_y, g_y_input)\n",
    "    \n",
    "    pm['w'] -= self.learning_rate * G_weight\n",
    "    pm['b'] -= self.learning_rate * G_bias\n",
    "    \n",
    "    return G_input\n",
    "\n",
    "MlpModel.forward_layer = mlp_forward_layer\n",
    "MlpModel.backprop_layer = mlp_backprop_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "411d00ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_forward_postproc(self, output, y):\n",
    "    loss, aux_loss = self.dataset.forward_postproc(output, y)\n",
    "    extra, aux_extra = self.forward_extra_cost(y)\n",
    "    return loss + extra, [aux_loss, aux_extra]\n",
    "\n",
    "def mlp_forward_extra_cost(self, y):\n",
    "    return 0, None\n",
    "\n",
    "MlpModel.forward_postproc = mlp_forward_postproc\n",
    "MlpModel.forward_extra_cost = mlp_forward_extra_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "107c1506",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_backprop_postproc(self, G_loss, aux):\n",
    "    aux_loss, aux_extra = aux\n",
    "    self.backprop_extra_cost(G_loss, aux_extra)\n",
    "    \n",
    "    G_output = self.dataset.backprop_postproc(G_loss, aux_loss)\n",
    "    \n",
    "    return G_output\n",
    "\n",
    "def mlp_backprop_extra_cost(self, G_loss, aux):\n",
    "    pass\n",
    "\n",
    "MlpModel.backprop_postproc = mlp_backprop_postproc\n",
    "MlpModel.backprop_extra_cost = mlp_backprop_extra_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3c8a1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_eval_accuracy(self, x, y, output = None):\n",
    "    if output is None:\n",
    "        output, _ = self.forward_neuralnet(x)\n",
    "    \n",
    "    accuracy = self.dataset.eval_accuracy(x, y, output)\n",
    "    return accuracy\n",
    "\n",
    "MlpModel.eval_accuracy = mlp_eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c717e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mlp_get_estimate(self, x):\n",
    "    output, _ = self.forward_neuralnet(x)\n",
    "    estimate = self.dataset.get_estimate(output)\n",
    "    return estimate\n",
    "\n",
    "MlpModel.get_estimate = mlp_get_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b43590e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(object):\n",
    "    def __init__(self, name, mode):\n",
    "        self.name = name\n",
    "        self.mode = mode\n",
    "    \n",
    "    def __str__(self):\n",
    "        return '{}({}, {}+{}+{})'.format(self.name, self.mode, len(self.tr_xs), len(self.te_xs), len(self.va_xs))\n",
    "    \n",
    "    def train_count(self):\n",
    "        return len(self.tr_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dd32ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_get_train_data(self, batch_size, nth):\n",
    "    from_idx = nth * batch_size\n",
    "    to_idx = (nth + 1) * batch_size\n",
    "    \n",
    "    tr_X = self.tr_xs[self.indices[from_idx : to_idx]]\n",
    "    tr_Y = self.tr_ys[self.indices[from_idx : to_idx]]\n",
    "    \n",
    "    return tr_X, tr_Y\n",
    "\n",
    "def dataset_shuffle_train_data(self, size):\n",
    "    self.indices = np.arange(size)\n",
    "    np.random.shuffle(self.indices)\n",
    "    \n",
    "\n",
    "Dataset.get_train_data = dataset_get_train_data\n",
    "Dataset.shuffle_train_data = dataset_shuffle_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c209b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_get_test_data(self):\n",
    "    return self.te_xs, self.te_ys\n",
    "\n",
    "Dataset.get_test_data = dataset_get_test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd08f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_get_validate_data(self, count):\n",
    "    self.va_indices = np.arange(len(self.va_xs))\n",
    "    np.random.shuffle(self.va_indices)\n",
    "    \n",
    "    va_X = self.va_xs[self.va_indices[0 : count]]\n",
    "    va_Y = self.va_ys[self.va_indices[0 : count]]\n",
    "    \n",
    "    return va_X, va_Y\n",
    "\n",
    "Dataset.get_validate_data = dataset_get_validate_data\n",
    "Dataset.get_visualize_data = dataset_get_validate_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "181d4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_shuffle_data(self, xs, ys, tr_ratio = 0.8, va_ratio = 0.8):\n",
    "    data_count = len(xs)\n",
    "    \n",
    "    tr_cnt = int(data_count * tr_ratio / 10) * 10\n",
    "    va_cnt = int(data_count * va_ratio)\n",
    "    te_cnt = data_count - (tr_cnt + va_cnt)\n",
    "    \n",
    "    tr_from, tr_to = 0, tr_cnt\n",
    "    va_from, va_to = tr_cnt, tr_cnt + va_cnt\n",
    "    te_from, te_to = tr_cnt + va_cnt, data_count\n",
    "    \n",
    "    indices = np.arange(data_count)\n",
    "    np.random.shuffle(indices)\n",
    "    \n",
    "    self.tr_xs = xs[indices[tr_from : tr_to]]\n",
    "    self.tr_ys = ys[indices[tr_from : tr_to]]\n",
    "    self.va_xs = xs[indices[va_from : va_to]]\n",
    "    self.va_ys = ys[indices[va_from : va_to]]\n",
    "    self.te_xs = xs[indices[te_from : te_to]]\n",
    "    self.te_ys = ys[indices[te_from : te_to]]\n",
    "    \n",
    "    self.input_shape = xs[0].shape\n",
    "    self.output_shape = ys[0].shape\n",
    "    \n",
    "    return indices[tr_from : tr_to], indices[va_from : va_to], indices[te_from : te_to]\n",
    "\n",
    "Dataset.shuffle_data = dataset_shuffle_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cfe9394d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_forward_postproc(self, output, y, mode = None):\n",
    "    if mode is None:\n",
    "        mode = self.mode\n",
    "    \n",
    "    if mode == 'regression':\n",
    "        diff = output - y\n",
    "        square = np.square(diff)\n",
    "        loss = np.mean(square)\n",
    "        aux = diff\n",
    "    elif mode == 'binary':\n",
    "        entropy = sigmoid_cross_with_logits(y, output)\n",
    "        loss = np.mean(entropy)\n",
    "        aux = [y, output]\n",
    "    elif mode == 'select':\n",
    "        entropy = softmax_cross_entropy_with_logits(y, output)\n",
    "        loss = np.mean(entropy)\n",
    "        aux = [output, y, entropy]\n",
    "    \n",
    "    return loss, aux\n",
    "\n",
    "Dataset.forward_postproc = dataset_forward_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b6852691",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_backprop_postproc(self, G_loss, aux, mode = None):\n",
    "    if mode is None:\n",
    "        mode = self.mode\n",
    "    \n",
    "    if mode == 'regression':\n",
    "        diff = aux\n",
    "        shape = diff.shape\n",
    "        \n",
    "        g_loss_square = np.ones(shape) / np.prod(shape)\n",
    "        g_square_diff = 2 * diff\n",
    "        g_diff_output = 1\n",
    "        \n",
    "        G_square = g_loss_square * G_loss\n",
    "        G_diff = g_square_diff * G_square\n",
    "        G_output_ = g_diff_output * G_diff\n",
    "        \n",
    "    elif mode == 'binary':\n",
    "        y, output = aux\n",
    "        shape = output.shape\n",
    "        \n",
    "        g_loss_entropy = np.ones(shape) / np.prod(shape)\n",
    "        g_entropy_output = sigmoid_cross_entropy_with_logits_derv(y, output)\n",
    "        \n",
    "        G_entropy = g_loss_entropy * G_loss\n",
    "        G_output_ = g_entropy_output * G_entropy\n",
    "    \n",
    "    elif mode == 'select':\n",
    "        output, y, entropy = aux\n",
    "        \n",
    "        g_loss_entropy = 1.0 / np.prod(entropy.shape)\n",
    "        g_entropy_output = softmax_cross_entropy_with_logits_derv(y, output)\n",
    "        \n",
    "        G_entropy = g_loss_entropy * G_loss\n",
    "        G_output_ = g_entropy_output * G_entropy\n",
    "        \n",
    "    return G_output_\n",
    "\n",
    "Dataset.backprop_postproc = dataset_backprop_postproc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "16210e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_eval_accuracy(self, x, y, output, mode = None):\n",
    "    if mode is None:\n",
    "        mode = self.mode\n",
    "    \n",
    "    if mode == 'regression':\n",
    "        mse = np.mean(np.square(output - y))\n",
    "        accuracy = 1 - np.sqrt(mse) / np.mean(y)\n",
    "    elif mode == 'binary':\n",
    "        estimate = np.greater(output, 0)\n",
    "        answer = np.equal(y, 1.0)\n",
    "        correct = np.equal(estimate, answer)\n",
    "        accuracy = np.mean(correct)\n",
    "    elif mode == 'select':\n",
    "        estimate = np.argmax(output, axis = 1)\n",
    "        answer = np.argmax(y, axis = 1)\n",
    "        correct = np.equal(estimate, answer)\n",
    "        accuracy = np.mean(correct)\n",
    "        \n",
    "    return accuracy\n",
    "\n",
    "Dataset.eval_accuracy = dataset_eval_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1a49da84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_get_estimate(self, output, mode = None):\n",
    "    if mode is None:\n",
    "        mode = self.mode\n",
    "    \n",
    "    if mode == 'regression':\n",
    "        estimate = output\n",
    "    elif mode == 'binary':\n",
    "        estimate = sigmoid(output)\n",
    "    elif mode == 'select':\n",
    "        estimate = softmax(output)\n",
    "    \n",
    "    return estimate\n",
    "\n",
    "Dataset.get_estimate = dataset_get_estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e4f2362a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_train_prt_result(self, epoch, costs, accs, acc, time1, time2):\n",
    "    print('    Epoch {} : cost = {:5.3f}, accuracy = {:5.3f}/{:5.3f} ({}/{} secs)'.format(epoch, np.mean(costs), np.mean(accs), acc, time1, time2))\n",
    "    \n",
    "def dataset_test_prt_result(self, name, acc, time):\n",
    "    print('    Model {} test report : accoracy = {:5.3f}, ({} secs)\\n'.format(name, acc, time))\n",
    "\n",
    "\n",
    "Dataset.train_prt_result = dataset_train_prt_result\n",
    "Dataset.test_prt_result = dataset_test_prt_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cb9b9ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbaloneDataset(Dataset):\n",
    "    def __init__(self):\n",
    "        super(AbaloneDataset, self).__init__('abalone', 'regression')\n",
    "        \n",
    "        rows, _ = load_csv(\"C:/Users/cheol/Downloads/Deep-Learning-Study-main/Deep-Learning-Study-main/Regression_Analysis/archive/abalone.csv\")\n",
    "        \n",
    "        xs = np.zeros([len(rows), 10])\n",
    "        ys = np.zeros([len(rows), 1])\n",
    "        \n",
    "        for n, row in enumerate(rows):\n",
    "            if row[0] == 'I':\n",
    "                xs[n, 0] = 1\n",
    "            if row[0] == 'M':\n",
    "                xs[n, 1] = 1\n",
    "            if row[0] == 'F':\n",
    "                xs[n, 2] = 1\n",
    "            \n",
    "            xs[n, 3:] = row[1:-1]\n",
    "            ys[n, :] = row[-1:]\n",
    "            \n",
    "        self.shuffle_data(xs, ys, 0.8)\n",
    "        \n",
    "    def visualize(self, xs, estimates, answers):\n",
    "        for n in range(len(xs)):\n",
    "            x, est, ans = xs[n], estimates[n], answers[n]\n",
    "            xstr = vector_to_str(x, '%4.2f')\n",
    "            print('{} => estimate {:4.1f} : answers {:4.1f}'.format(xstr, est[0], ans[0]))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1060cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(x):\n",
    "    return np.maximum(x, 0)\n",
    "\n",
    "def relu_dev(y):\n",
    "    return np.sign(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2a6d7359",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return np.exp(-relu(-x)) / (1.0 + np.exp(-np.abs(x)))\n",
    "\n",
    "def sigmoid_derv(y):\n",
    "    return y * (1 - y)\n",
    "\n",
    "def sigmoid_cross_entropy_with_logits(z, x):\n",
    "    return relu(x) - x * z + np.log(1 + np.exp(-np.abs(x)))\n",
    "\n",
    "def sigmoid_cross_entropy_with_logits_derv(z, x):\n",
    "    return -z + sigmoid(x)\n",
    "\n",
    "def tanh(x):\n",
    "    return 2 * sigmoid(2*x) - 1\n",
    "\n",
    "def tanh_derv(y):\n",
    "    return (1.0 + y) * (1.0 - y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0c83ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    max_elem = np.max(x, axis = 1)\n",
    "    diff = (x.transpose() - max_elem).transpose()\n",
    "    exp = np.exp(diff)\n",
    "    sum_exp = np.sum(exp, axis = 1)\n",
    "    probs = (exp.transpose() / sum_exp).transpose()\n",
    "    return probs\n",
    "\n",
    "def softmax_cross_entropy_with_logits(labels, logits):\n",
    "    probs = softmax(logits)\n",
    "    return -np.sum(labels * np.log(probs + 1.0e-10), axis = 1)\n",
    "\n",
    "def softmax_cross_entropy_with_logits_derv(labels, logits):\n",
    "    return softmax(logits) - labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f16356c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path, skip_header = True):\n",
    "    with open(path) as csvfile:\n",
    "        csvreader = csv.reader(csvfile)\n",
    "        headers = None\n",
    "        if skip_header:\n",
    "            headers = next(csvreader, None)\n",
    "        rows = []\n",
    "        for row in csvreader:\n",
    "            rows.append(row)\n",
    "    \n",
    "    return rows, headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cb6e588a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def onehot(xs, cnt):\n",
    "    return np.eye(cnt)[np.array(xs).astype(int)]\n",
    "\n",
    "def vector_to_str(x, fmt = '%.2f', max_cnt = 0):\n",
    "    if max_cnt == 0 or len(x) <= max_cnt:\n",
    "        return '[' + ','.join([fmt]*len(x)) % tuple(x) + ']'\n",
    "    \n",
    "    v = x[0:max_cnt]\n",
    "    \n",
    "    return '[' + ','.join([fmt]*len(v)) % tuple(v) + ',...]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "10df2c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ad = AbaloneDataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03398a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "am = MlpModel('abalone_model', ad, [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d4ca241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model abalone_model train started:\n",
      "    Epoch 2 : cost = 8.128, accuracy = 0.734/0.697 (1/1 secs)\n",
      "    Epoch 4 : cost = 7.388, accuracy = 0.745/0.715 (0/1 secs)\n",
      "    Epoch 6 : cost = 7.242, accuracy = 0.748/0.741 (0/1 secs)\n",
      "    Epoch 8 : cost = 7.133, accuracy = 0.748/0.728 (0/1 secs)\n",
      "    Epoch 10 : cost = 7.051, accuracy = 0.751/0.720 (0/1 secs)\n",
      "Model abalone_model train ended in 1 secs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheol\\anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3440: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Model abalone_model test report : accoracy =   nan, (5 secs)\n",
      "\n",
      "Model abalone_model visualization\n",
      "[1.00,0.00,0.00,0.45,0.36,0.13,0.48,0.19,0.13,0.14] => estimate  8.2 : answers  7.0\n",
      "[0.00,0.00,1.00,0.61,0.47,0.15,1.03,0.45,0.25,0.28] => estimate 11.1 : answers  9.0\n",
      "[0.00,0.00,1.00,0.65,0.52,0.21,1.50,0.56,0.32,0.42] => estimate 12.6 : answers 16.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheol\\anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "am.exec_all(epoch_count = 10, report = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32e5139",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ebc41d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
